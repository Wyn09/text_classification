{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections.abc import Iterable, Iterator\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  当模型在推理过程中遇到了字典中没有包含的token时，会出现key index错误, Out Of Value (OOV问题)\n",
    "##### 解决方案：通过特殊token：\\<UNK\\> 替代没有见过的token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommentDataset:\n",
    "    def __init__(self, comments, labels):\n",
    "        self.comments, self.labels = comments, labels\n",
    "    \n",
    "        # 字典构建 (字符为token / 词汇为token)\n",
    "        self._build_vocab()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        token_index = [self.vocab.get(tk, self.vocab[\"<UNK>\"]) for tk in self.comments[index]]\n",
    "        index_tensor = torch.zeros(size=(125,))\n",
    "        for i in range(len(token_index)):\n",
    "            index_tensor[i] = token_index[i]\n",
    "        return index_tensor, torch.tensor(self.labels[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def _build_vocab(self): # 自定义内置函数(_:不希望用户调用)\n",
    "        tokens = set()\n",
    "        for cmt in self.comments:\n",
    "            tokens.update(list(cmt))\n",
    "        tokens = [\"<PAD>\", \"<UNK>\"] + list(tokens)\n",
    "        self.vocab = {token:i for i, token in enumerate(tokens)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(isinstance(CommentDataset, Iterator))\n",
    "print(isinstance(CommentDataset, Iterable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>什么破烂反派，毫无戏剧冲突能消耗两个多小时生命，还强加爱情戏 脑残片好圈钱倒是真的</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>说实话其实剧情就那样吧，非漫威粉看着可能有的地方会get不到G点吧 （其实漫威卖的不是剧情...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>没有了洛基这个小基仔真是觉得即墨如雪啊</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>看毕，我激动地对友人说，等等奥创要来毁灭台北怎么办厚，她拍了拍我肩膀，没事，反正你买了两份...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>不出意料得烂，喜欢这部电影的孩子，大概也喜欢变4……</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256031</th>\n",
       "      <td>我只能用搞笑的标签，可惜没有吐槽的标签！</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256032</th>\n",
       "      <td>剧情逗比,调色二比,绝色塑造无力,渣渣</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256039</th>\n",
       "      <td>不给行业毒瘤乐视和陆川送一毛钱，雇佣水军黑港囧，电影上映第二天就散播港囧的高清电影复刻版拷...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256043</th>\n",
       "      <td>浪费时间浪费钱，虽然是9.9的特价票，我还是觉得不值</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256048</th>\n",
       "      <td>奔跑吧，不知羞耻的少年少女们！一星给红犼身上的毛！</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Comment  labels\n",
       "15             什么破烂反派，毫无戏剧冲突能消耗两个多小时生命，还强加爱情戏 脑残片好圈钱倒是真的        0\n",
       "21       说实话其实剧情就那样吧，非漫威粉看着可能有的地方会get不到G点吧 （其实漫威卖的不是剧情...       1\n",
       "25                                    没有了洛基这个小基仔真是觉得即墨如雪啊       1\n",
       "40       看毕，我激动地对友人说，等等奥创要来毁灭台北怎么办厚，她拍了拍我肩膀，没事，反正你买了两份...       1\n",
       "43                             不出意料得烂，喜欢这部电影的孩子，大概也喜欢变4……       0\n",
       "...                                                   ...     ...\n",
       "256031                               我只能用搞笑的标签，可惜没有吐槽的标签！       0\n",
       "256032                                剧情逗比,调色二比,绝色塑造无力,渣渣       0\n",
       "256039   不给行业毒瘤乐视和陆川送一毛钱，雇佣水军黑港囧，电影上映第二天就散播港囧的高清电影复刻版拷...       0\n",
       "256043                         浪费时间浪费钱，虽然是9.9的特价票，我还是觉得不值       0\n",
       "256048                          奔跑吧，不知羞耻的少年少女们！一星给红犼身上的毛！       0\n",
       "\n",
       "[20000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([' 什么破烂反派，毫无戏剧冲突能消耗两个多小时生命，还强加爱情戏 脑残片好圈钱倒是真的 ',\n",
       "       ' 说实话其实剧情就那样吧，非漫威粉看着可能有的地方会get不到G点吧 （其实漫威卖的不是剧情而是人物和世界观呀，漫威宇宙棒棒哒）但对于漫威粉来说真是全程高能+IMAX燃爆啊！#漫威大法好#'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle(\"../data/comments.bin\")\n",
    "display(data)\n",
    "comments, labels = data[\"Comment\"].values, data[\"labels\"].values\n",
    "comments[[0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([2446., 2836.,  814., 2421., 1492., 3508., 3931., 1073.,  946., 3037.,\n",
      "        3905., 1437., 2188., 3736.,  711., 1794., 1767., 4277., 3443., 1305.,\n",
      "        3686., 3460., 1188., 4035., 1073., 3988., 1560., 1729., 2616., 1447.,\n",
      "        3905., 2446., 2362., 2461., 3025.,  268.,  372., 2553., 1731., 3547.,\n",
      "        2517., 3974., 2446.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.]), tensor(0, dtype=torch.int32))\n",
      "(tensor([2446., 2836.,  814., 2421., 1492., 3508., 3931., 1073.,  946., 3037.,\n",
      "        3905., 1437., 2188., 3736.,  711., 1794., 1767., 4277., 3443., 1305.,\n",
      "        3686., 3460., 1188., 4035., 1073., 3988., 1560., 1729., 2616., 1447.,\n",
      "        3905., 2446., 2362., 2461., 3025.,  268.,  372., 2553., 1731., 3547.,\n",
      "        2517., 3974., 2446.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.]), tensor(0, dtype=torch.int32))\n"
     ]
    }
   ],
   "source": [
    "ds = CommentDataset(comments, labels)\n",
    "for item in ds:\n",
    "    print(item)\n",
    "    break\n",
    "print(next(iter(ds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<PAD>', '<UNK>', '截', '孱', '贤', '捂', '鋼', '盗', '議', '碰']\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(list(ds.vocab.keys())[:10])\n",
    "print(list(ds.vocab.values())[:10])\n",
    "print(ds.vocab[\"<PAD>\"])\n",
    "print(ds.vocab[\"<UNK>\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 125])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(ds, batch_size=10, shuffle=True)\n",
    "next(iter(dl))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "625\n"
     ]
    }
   ],
   "source": [
    "print(len(ds))\n",
    "print(len(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommentsClassifier(nn.Module):\n",
    "    def __init__(self, vocab_szie, embedding_size, rnn_hidden_size, num_labels):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_szie, embedding_size, padding_idx=0)\n",
    "        self.rnn = nn.LSTM(input_size=embedding_size, hidden_size=rnn_hidden_size, batch_first=True)\n",
    "        self.classifier = nn.Linear(rnn_hidden_size, num_labels)\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        out = self.emb(X) # (batch_size, seq_len, embedding_size)\n",
    "        output,_ = self.rnn(out) # (batch_size, seq_len, rnn_hidden_size)\n",
    "        return self.classifier(output[:,-1,:]) # (batch_size, num_labels)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randint(1, 10, size=(10, 12))\n",
    "model = CommentsClassifier(vocab_szie=10, embedding_size=30, rnn_hidden_size=20, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 2])\n"
     ]
    }
   ],
   "source": [
    "result = model(X)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 0.6926: 100%|██████████| 625/625 [00:05<00:00, 113.96it/s]\n",
      "epoch: 2, loss: 0.6914: 100%|██████████| 625/625 [00:05<00:00, 117.45it/s]\n",
      "epoch: 3, loss: 0.6939: 100%|██████████| 625/625 [00:05<00:00, 117.54it/s]\n",
      "epoch: 4, loss: 0.6907: 100%|██████████| 625/625 [00:05<00:00, 116.77it/s]\n",
      "epoch: 5, loss: 0.6928: 100%|██████████| 625/625 [00:05<00:00, 110.26it/s]\n"
     ]
    }
   ],
   "source": [
    "class CommentDataset:\n",
    "    def __init__(self, comments, labels):\n",
    "        self.comments, self.labels = comments, labels\n",
    "    \n",
    "        # 字典构建 (字符为token / 词汇为token)\n",
    "        self._build_vocab()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        token_index = [self.vocab.get(tk, self.vocab[\"<UNK>\"]) for tk in self.comments[index]]\n",
    "        index_tensor = torch.zeros(size=(125,), dtype=torch.long)\n",
    "        for i in range(len(token_index)):\n",
    "            index_tensor[i] = token_index[i]\n",
    "        return index_tensor, torch.tensor(self.labels[index], dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def _build_vocab(self): # 自定义内置函数(_:不希望用户调用)\n",
    "        tokens = set()\n",
    "        for cmt in self.comments:\n",
    "            tokens.update(list(cmt))\n",
    "        tokens = [\"<PAD>\", \"<UNK>\"] + list(tokens)\n",
    "        self.vocab = {token:i for i, token in enumerate(tokens)} \n",
    "\n",
    "batch_size = 32\n",
    "lr = 1e-4\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "epoch = 5\n",
    "embedding_size = 200\n",
    "rnn_hidden_size = 100\n",
    "num_labels = 2\n",
    "\n",
    "data = pd.read_pickle(\"../data/comments.bin\")\n",
    "comments, labels = data[\"Comment\"].values, data[\"labels\"].values\n",
    "\n",
    "ds = CommentDataset(comments, labels)\n",
    "dl = DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "class CommentsClassifier(nn.Module):\n",
    "    def __init__(self, vocab_szie, embedding_size, rnn_hidden_size, num_labels):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_szie, embedding_size, padding_idx=0)\n",
    "        self.rnn = nn.LSTM(input_size=embedding_size, hidden_size=rnn_hidden_size, batch_first=True)\n",
    "        self.classifier = nn.Linear(rnn_hidden_size, num_labels)\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        out = self.emb(X) # (batch_size, seq_len, embedding_size)\n",
    "        output,_ = self.rnn(out) # (batch_size, seq_len, rnn_hidden_size)\n",
    "        return self.classifier(output[:,-1,:]) # (batch_size, num_labels)\n",
    "        pass\n",
    "\n",
    "model = CommentsClassifier(\n",
    "    vocab_szie=len(ds.vocab),\n",
    "    embedding_size=embedding_size,\n",
    "    rnn_hidden_size=rnn_hidden_size,\n",
    "    num_labels=num_labels\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn = loss_fn.to(device)\n",
    "\n",
    "for e in range(epoch):\n",
    "    process_bar = tqdm(dl)\n",
    "    for cmt, lbl in process_bar:\n",
    "        cmt, lbl = cmt.to(device), lbl.to(device)\n",
    "        y_hat = model(cmt)\n",
    "        loss = loss_fn(y_hat, lbl)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        process_bar.set_description(f\"epoch: {e + 1}, loss: {loss.item():.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
